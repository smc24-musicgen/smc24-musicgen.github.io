---
layout: schedule
permalink: /lectures/
title: Lectures
---

* (The list will be replaced with the table of contents.)
{:toc}

***

## Part 1

### Class 1: Course Introduction

When: January 8th at 17:00-18:00h (online).

What: 

* Introduction to the course, its structure, philosophy, and evaluation.  
* Discussion about the history of generative music, ethical aspects, music representation, and generative techniques.

Before taking this class, students are expected to have watched the following videos from The Sound of AI’s *Generative Music AI Course*:

1. [What's Generative Music?](https://www.youtube.com/watch?v=9QNG56fc_l8&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=2)  
2. [History of Generative Music](https://www.youtube.com/watch?v=3znKoIUrgDI&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=3)  
3. [Use Cases](https://www.youtube.com/watch?v=Fg3TGfbEL64&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=4)  
4. [Ethical Implications](https://www.youtube.com/watch?v=DCaE5776Rqg&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=5)  
5. [Symbolic Vs Audio Generation](https://www.youtube.com/watch?v=VYxcHHJNTR0&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=6)  
6. [Generative Techniques](https://www.youtube.com/watch?v=W-_eWSrQ_vU&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=7)  
7. [Limitations and Future Vision](https://www.youtube.com/watch?v=viR9q61wV4Q&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=8)

### Class 2: Genetic Algorithms

When: January 13th at 16:00-17:10h (in presence).

What: 

* Genetic algorithms for music generation.  
* Real-world experience / challenges implementing this technique.  
* Discuss GenJam system.  
* Exercises and practical challenges.

Before taking this class, students are expected to have watched the following videos and coded along the code walkthrough from The Sound of AI’s *Generative Music AI Course:*

1. Genetic Algorithms \[[video](https://www.youtube.com/watch?v=CAVy7OZ87mE&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=15)\] \[[slides](https://github.com/musikalkemist/generativemusicaicourse/blob/main/15.%20Genetic%20algorithms/Slides/15.%20Genetic%20algorithms.pdf)\]  
2. Melody Harmonization with Genetic Algorithms \[[video](https://www.youtube.com/watch?v=AmtLrd-cYSY&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=16)\] \[[code](https://github.com/musikalkemist/generativemusicaicourse/blob/main/16.%20Melody%20harmonization%20with%20genetic%20algorithms/Code/geneticmelodyharmonizer.py)\]

### Class 3: Markov Chains

When: January 13th at 17:20-18:30h (in presence).

What: 

* Markov chains models for music generation.  
* Real-world experience / challenges implementing this technique.  
* Discuss GEDMAS system.  
* Exercises and practical challenges.

Before taking this class, students are expected to have watched the following videos and coded along the code walkthrough from The Sound of AI’s *Generative Music AI Course:*

1. Markov Chains \[[video](https://www.youtube.com/watch?v=gn-_ocUaGYo&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=11)\] \[[slides](https://github.com/musikalkemist/generativemusicaicourse/blob/main/11.%20Markov%20chains/Slides/11.%20Markov%20chains.pdf)\]  
2. Melody Generation with Markov Chains \[[video](https://www.youtube.com/watch?v=V7OPB6zmSdM&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=12)\] \[[code](https://github.com/musikalkemist/generativemusicaicourse/blob/main/12.%20Melody%20generation%20with%20Markov%20chains/Code/markovchain.py)\]

### Class 4: RNN/LSTMs

When: January 14th at 16:00-18:30h (in presence).

What: 

* RNN/LSTMs for music generation.  
* Real-world experience / challenges implementing this technique.  
* Discuss BachBot system.  
* Exercises and practical challenges.

Before taking this class, students are expected to have watched the following videos and coded along the code walkthroughs from The Sound of AI YouTube channel*:*

1. Recurrent Neural Networks Explained Easily \[[video](https://www.youtube.com/watch?v=DY82Goknf0s)\] \[[slides](https://github.com/musikalkemist/DeepLearningForAudioWithPython/tree/master/17-%20Recurrent%20Neural%20Networks%20explained%20easily/slides)\]  
2. Long Short Term Memory (LSTM) Networks Explained Easily \[[video](https://www.youtube.com/watch?v=eCvz-kB4yko)\] \[[slides](https://github.com/musikalkemist/DeepLearningForAudioWithPython/tree/master/18-%20LSTM%20networks%20explained%20easily/slides)\]  
3. *Generating Melodies with LSTM Nets Course*:  
   1. [Video lectures (theory \+ implementation)](https://www.youtube.com/watch?v=FLr0r-QhqH0&list=PL-wATfeyAMNr0KMutwtbeDCmpwvtul-Xz)  
   2. [Code \+ slides](https://github.com/musikalkemist/generating-melodies-with-rnn-lstm/tree/master)

### Class 5: Transformers

When: January 15th at 16:00-18:30h (in presence).

What: 

* Transformers for music generation.  
* Real-world experience / challenges implementing this technique.  
* Focus on Music Transformer.  
* Exercises and practical challenges.

Before taking this class, students are expected to have watched the following videos and coded along the code walkthrough from The Sound of AI’s *Generative Music AI Course:*

1. Transformers Explained Easily: Part 1 \[[video](https://www.youtube.com/watch?v=FtXT-AFzSvg&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=17)\] \[[slides](https://github.com/musikalkemist/generativemusicaicourse/blob/main/17.%20Transformers%20-%20Part%201/Slides/17.%20Transformers%20-%20Part%201.pdf)\]  
2. Transformers Explained Easily: Part 2 \[[video](https://www.youtube.com/watch?v=ctbvMnbylsA&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=18)\] \[[slides](https://github.com/musikalkemist/generativemusicaicourse/blob/main/18.%20Transformers%20-%20Part%202/Slides/18.%20Transformers%20Part%202.pdf)\]  
3. Melody Generation with Transformers \[[video](https://www.youtube.com/watch?v=j4LABY2d7k4&list=PL-wATfeyAMNqAPjwGT3ikEz3gMo23pl-D&index=19)\] \[[code](https://github.com/musikalkemist/generativemusicaicourse/tree/main/19.%20Melody%20generation%20with%20transformers/Code)\]

### Class 6: Assignments Review

When: January 27th at 16:00-18:30h (in presence).

What: 

* Discuss four code assignments.  
* Check solutions together.

### Class 7: Paper Implementation

When: January 28th at 16:30-18:30h (in presence).

What: 

* How to implement a generative AI music paper.  
* Check paper implementation together. 

### Class 8: Creative Reverse Engineering \+ Wrap-up

When: January 29th at 9:30-11:30h (in presence).

What: 

* Reverse engineer the output of a generative music system.  
* During the class, in groups of three people, design a generative music system that can come up with the presented music output.  
* Reflect on Part 1 of the course, ask questions, tips to get a job as a gen AI music engineer. 

### Hands-on Demo: Transformers Hack Session

When: TBD for 1:30h (in presence).

What: 

* Inference \+ Fine Tuning with Hugging Face Transformers.  
* Using pre-trained symbolic models  (no details, only what they do, as a user rather than a "researcher").  
* On one of the cloud providers \- AWS, Azure, GCP.

Before taking this class, students are expected to have installed the following libraries and coded along the code walkthrough:

1. Set up an account on cloud computing platforms \[AWS/GCP/Azure (TBD)\]  
2. Hugging Face Transformers \[[blog](https://huggingface.co/docs/transformers/en/quicktour)\]  
3. Hugging Face MuPT \[[blog](https://huggingface.co/m-a-p/MuPT-v1-8192-190M)\]

## Part 2

### Week 1: Audio modeling Introduction

When:
February 3 at 16:30:00-18:00h.
February 5 at 17:00-18:00h.

What:

* Introduction to the second part of the course on generative audio.
* Discussion about the main ideas, audio representations, and architectures commonly used.
* Sound Model Factory approach to creating playable audio models.

Class preparation :

1. Engel, J., Agrawal, K. K., Chen, S., Gulrajani, I., Donahue, C., & Roberts, A. **(2019**). **Gansynth**: Adversarial neural audio synthesis. *arXiv preprint arXiv:1902.08710*.  [[Link]](https://arxiv.org/abs/1902.08710)
2. Wyse, L., Kamath, P., & Gupta, C. (2022, April). Sound model factory: An integrated system architecture for generative audio modelling. In *International Conference on Computational Intelligence in Music, Sound, Art and Design (Part of EvoStar)* (pp. 308-322). Cham: Springer International Publishing. [[Link]](https://arxiv.org/abs/2206.13085)

### Week 2: Representation

When:
February 10 at 16:30:00-18:00h.
February 12 at 17:00-18:00h.

### Week 3: Codecs

When:
February 17 at 16:30:00-18:00h.
February 19 at 17:00-18:00h.

### Week 4: DDSP and Rave

When:
February 24 at 16:30:00-18:00h.
February 26 at 17:00-18:00h.

### Week 5: Transformers for Audio

When:
March 3 at 16:30:00-18:00h.
March 5 at 17:00-18:00h.
